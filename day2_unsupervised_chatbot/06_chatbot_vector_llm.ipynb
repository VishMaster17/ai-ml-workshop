{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# \ud83e\udd16 AI-Powered Chatbot using FAISS + OpenAI\n", "In this notebook, you'll learn how to:\n", "- Chunk a document and convert it into embeddings\n", "- Store embeddings in a FAISS vector database\n", "- Perform similarity search\n", "- Generate responses using OpenAI LLM (GPT-3.5/4)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \u2705 Step 1: Install required libraries\n", "!pip install faiss-cpu openai tiktoken --quiet"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83d\udee0\ufe0f Step 2: Setup API Key and Imports\n", "_Note: Replace `'your-openai-api-key'` with your actual key during live demo_"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os\n", "import openai\n", "import faiss\n", "import numpy as np\n", "from sklearn.metrics.pairwise import cosine_similarity\n", "from typing import List\n", "\n", "# Set your API key (use environment variable or manual input for security)\n", "openai.api_key = \"your-openai-api-key\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83d\udcc4 Step 3: Sample Knowledge Base (You can replace this with file upload)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["text_chunks = [\n", "    \"Python is a high-level programming language.\",\n", "    \"Machine learning involves training models on data.\",\n", "    \"OpenAI provides APIs for language models like GPT.\",\n", "    \"FAISS is a library for efficient similarity search.\",\n", "    \"You can build chatbots using vector search and LLMs.\"\n", "]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \u2728 Step 4: Convert text chunks into embeddings using OpenAI API"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_embedding(text):\n", "    response = openai.Embedding.create(\n", "        input=text,\n", "        model=\"text-embedding-ada-002\"\n", "    )\n", "    return np.array(response['data'][0]['embedding'])\n", "\n", "embeddings = [get_embedding(chunk) for chunk in text_chunks]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83d\udce6 Step 5: Store Embeddings in FAISS Index"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dimension = len(embeddings[0])\n", "index = faiss.IndexFlatL2(dimension)\n", "index.add(np.array(embeddings))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83d\udd0d Step 6: Perform Similarity Search on a Query"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["query = \"How do I build a chatbot?\"\n", "query_vec = get_embedding(query).reshape(1, -1)\n", "D, I = index.search(query_vec, k=2)\n", "\n", "print(\"Top Matching Chunks:\")\n", "for i in I[0]:\n", "    print('-', text_chunks[i])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83e\udde0 Step 7: Generate Answer from Context using OpenAI LLM"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["context = \"\\n\".join([text_chunks[i] for i in I[0]])\n", "prompt = f\"Answer the question based on the following context:\\n{context}\\n\\nQuestion: {query}\\nAnswer:\"\n", "\n", "response = openai.ChatCompletion.create(\n", "    model=\"gpt-3.5-turbo\",\n", "    messages=[\n", "        {\"role\": \"user\", \"content\": prompt}\n", "    ]\n", ")\n", "\n", "print(\"\\nResponse:\\n\", response['choices'][0]['message']['content'])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\ud83c\udfaf **Try it Yourself**: Replace the knowledge base or prompt to make your own chatbot!"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.8"}}, "nbformat": 4, "nbformat_minor": 4}