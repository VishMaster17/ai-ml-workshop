{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yaoObYLOlrI5",
        "outputId": "b9dc6a2c-2f9e-46be-a112-ac547c42f3de"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "\n",
        "# Create a simple spam dataset\n",
        "def create_spam_dataset():\n",
        "    messages = [\n",
        "        {\"message\": \"Congratulations! You've won a free prize. Claim now!\", \"label\": \"spam\"},\n",
        "        {\"message\": \"Hey, can we meet at 5pm today for coffee?\", \"label\": \"ham\"},\n",
        "        {\"message\": \"URGENT: Your account has been suspended. Reply immediately.\", \"label\": \"spam\"},\n",
        "        {\"message\": \"Don't forget to bring the documents for tomorrow's meeting.\", \"label\": \"ham\"},\n",
        "        {\"message\": \"FREE entry to concert this weekend! Limited tickets!\", \"label\": \"spam\"},\n",
        "        {\"message\": \"I'll be home late tonight, please feed the dog.\", \"label\": \"ham\"},\n",
        "        {\"message\": \"Buy now! 80% off on all products. Limited time offer.\", \"label\": \"spam\"},\n",
        "        {\"message\": \"The project deadline has been extended to next Friday.\", \"label\": \"ham\"},\n",
        "        {\"message\": \"Click here to claim your inheritance from a distant relative.\", \"label\": \"spam\"},\n",
        "        {\"message\": \"The doctor's appointment is confirmed for Thursday at 2pm.\", \"label\": \"ham\"},\n",
        "        {\"message\": \"Win a new iPhone! Just fill out this quick survey.\", \"label\": \"spam\"},\n",
        "        {\"message\": \"Can you pick up some groceries on your way home?\", \"label\": \"ham\"},\n",
        "    ]\n",
        "    return pd.DataFrame(messages)\n",
        "\n",
        "# Create dataset\n",
        "df = create_spam_dataset()\n",
        "\n",
        "# Display the dataset\n",
        "print(\"Message Dataset:\")\n",
        "for i, row in df.iterrows():\n",
        "    print(f\"{i+1}. [{row['label'].upper()}] {row['message']}\")\n",
        "\n",
        "# Create features using bag of words approach\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(df['message'])\n",
        "y = df['label']\n",
        "\n",
        "# Show feature names (words)\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "print(\"\\nVocabulary (unique words):\")\n",
        "print(feature_names)\n",
        "\n",
        "# Show document-term matrix\n",
        "X_array = X.toarray()\n",
        "df_bow = pd.DataFrame(X_array, columns=feature_names)\n",
        "print(\"\\nBag of Words representation:\")\n",
        "print(df_bow)\n",
        "\n",
        "# Create and train the Naive Bayes model\n",
        "model = MultinomialNB()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Print prior probabilities\n",
        "print(\"\\nPrior Probabilities:\")\n",
        "print(f\"P(spam) = {model.class_count_[0]/sum(model.class_count_):.4f}\")\n",
        "print(f\"P(ham) = {model.class_count_[1]/sum(model.class_count_):.4f}\")\n",
        "\n",
        "# Get feature (word) probabilities\n",
        "feature_prob = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Spam Probability': model.feature_log_prob_[0],\n",
        "    'Ham Probability': model.feature_log_prob_[1]\n",
        "})\n",
        "\n",
        "# Convert from log probabilities to actual probabilities\n",
        "feature_prob['Spam Probability'] = np.exp(feature_prob['Spam Probability'])\n",
        "feature_prob['Ham Probability'] = np.exp(feature_prob['Ham Probability'])\n",
        "\n",
        "# Add a ratio column to see which words are most indicative of spam\n",
        "feature_prob['Spam/Ham Ratio'] = feature_prob['Spam Probability'] / feature_prob['Ham Probability']\n",
        "\n",
        "# Sort by ratio to see most spam-indicative words\n",
        "spam_words = feature_prob.sort_values('Spam/Ham Ratio', ascending=False)\n",
        "print(\"\\nTop spam-indicative words:\")\n",
        "print(spam_words.head(10))\n",
        "\n",
        "# Sort to see most ham-indicative words\n",
        "ham_words = feature_prob.sort_values('Spam/Ham Ratio')\n",
        "print(\"\\nTop ham-indicative words:\")\n",
        "print(ham_words.head(10))\n",
        "\n",
        "# Visualize word probabilities\n",
        "plt.figure(figsize=(12, 6))\n",
        "# Select top N words from each class\n",
        "top_n = 10\n",
        "top_spam_features = spam_words.head(top_n)['Feature'].values\n",
        "top_ham_features = ham_words.head(top_n)['Feature'].values\n",
        "\n",
        "# Combine unique features\n",
        "top_features = set(top_spam_features) | set(top_ham_features)\n",
        "top_features = list(top_features)[:15]  # Limit to 15 words\n",
        "\n",
        "# Get probabilities for selected features\n",
        "selected_probs = feature_prob[feature_prob['Feature'].isin(top_features)]\n",
        "selected_probs = selected_probs.sort_values('Spam/Ham Ratio', ascending=False)\n",
        "\n",
        "# Plot\n",
        "x = range(len(selected_probs))\n",
        "width = 0.35\n",
        "plt.bar([i - width/2 for i in x], selected_probs['Spam Probability'], width, label='Spam', color='red', alpha=0.7)\n",
        "plt.bar([i + width/2 for i in x], selected_probs['Ham Probability'], width, label='Ham', color='green', alpha=0.7)\n",
        "plt.xticks(x, selected_probs['Feature'], rotation=45)\n",
        "plt.ylabel('Probability')\n",
        "plt.title('Word Probabilities in Spam vs. Ham')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Test on new messages\n",
        "test_messages = [\n",
        "    \"Congratulations! You won a free vacation to Hawaii!\",\n",
        "    \"Hey, do you want to go to the movies tonight?\",\n",
        "    \"URGENT: Your bank account needs verification immediately\",\n",
        "    \"Please bring the report to the meeting tomorrow\",\n",
        "    \"FREE GIFT waiting for you! Click now to claim!\"\n",
        "]\n",
        "\n",
        "# Function to explain prediction\n",
        "def explain_prediction(message, model, vectorizer):\n",
        "    # Transform the message\n",
        "    X_test = vectorizer.transform([message])\n",
        "\n",
        "    # Get prediction and probability\n",
        "    prediction = model.predict(X_test)[0]\n",
        "    probs = model.predict_proba(X_test)[0]\n",
        "\n",
        "    # Get word counts for this message\n",
        "    words = X_test.toarray()[0]\n",
        "    word_counts = []\n",
        "    for i, count in enumerate(words):\n",
        "        if count > 0:\n",
        "            word = vectorizer.get_feature_names_out()[i]\n",
        "            # Get probabilities for this word\n",
        "            spam_prob = np.exp(model.feature_log_prob_[0][i])\n",
        "            ham_prob = np.exp(model.feature_log_prob_[1][i])\n",
        "            word_counts.append((word, count, spam_prob, ham_prob, spam_prob/ham_prob))\n",
        "\n",
        "    # Sort by spam/ham ratio\n",
        "    word_counts.sort(key=lambda x: x[4], reverse=True)\n",
        "\n",
        "    # Print results\n",
        "    print(f\"\\nMessage: {message}\")\n",
        "    print(f\"Prediction: {prediction.upper()}\")\n",
        "    print(f\"Confidence: {max(probs):.2%}\")\n",
        "    print(f\"Probabilities: Spam={probs[0]:.2%}, Ham={probs[1]:.2%}\")\n",
        "\n",
        "    print(\"\\nTop words influencing classification:\")\n",
        "    for word, count, spam_p, ham_p, ratio in word_counts[:5]:\n",
        "        indicator = \"→ SPAM\" if spam_p > ham_p else \"→ HAM\"\n",
        "        print(f\"  {word}: {indicator} (Spam: {spam_p:.4f}, Ham: {ham_p:.4f}, Ratio: {ratio:.2f})\")\n",
        "\n",
        "# Test the classifier\n",
        "print(\"\\n=== Testing the classifier on new messages ===\")\n",
        "for message in test_messages:\n",
        "    explain_prediction(message, model, vectorizer)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
